# DCGAN Image Generation

This project implements a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from the CIFAR-10 dataset. The generator creates fake images, while the discriminator learns to distinguish between real and fake images.


## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Model Architecture](#model-architecture)
- [Training](#training)
- [Results](#results)
- [License](#license)

## Installation

To get started with the DCGAN project, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/mohammadreza-mohammadi94/DCGAN.git
   cd DCGAN
   ```

2. Install the required libraries:
   ```bash
   pip install torch torchvision
   ```

3. Ensure you have access to a compatible GPU (optional but recommended for training speed).

## Usage

1. Run the training script
2. The model will download the CIFAR-10 dataset if it is not already available in the specified directory (`/data`).
3. Monitor the training process in the console. The generator will produce images, and the losses for both the generator and discriminator will be printed.

## Model Architecture

### Generator
The generator network transforms a random noise vector (latent space) into a 64x64 RGB image through several transposed convolutional layers, utilizing instance normalization and ReLU activation functions. The output is generated using a Tanh activation function, scaling pixel values to the range [-1, 1].

### Discriminator
The discriminator network classifies images as real or fake. It downsamples the input image using several convolutional layers with LeakyReLU activation and batch normalization, finally outputting a single scalar probability value using a Sigmoid activation function.

## Training

The training loop consists of the following steps:
1. Update the discriminator's weights by training it on both real images from the dataset and fake images generated by the generator.
2. Update the generator's weights based on the discriminator's feedback to improve its image generation capabilities.
3. Save generated images every 100 steps and print the loss for both networks to monitor the training progress.

## Results

The generated images and real samples will be saved in the `results` directory. You can find the images with filenames indicating their respective epochs.

## License

This project is licensed under the MIT License. See the LICENSE file for more details.
